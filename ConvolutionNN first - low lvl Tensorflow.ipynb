{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "import os\n",
    "from os.path import isfile, isdir, join\n",
    "import ntpath\n",
    "\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "\n",
    "import cv2\n",
    "\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SELECT EXPERIMENT SAMPLE\n",
    "#sample_path = 'experiment-samples/trivial'\n",
    "#sample_path = 'experiment-samples/extra-small'\n",
    "#sample_path = 'experiment-samples/small-pabk'\n",
    "#sample_path = 'experiment-samples-nogit/medium'\n",
    "#sample_path = 'experiment-samples-nogit/large-pabk'\n",
    "sample_path = 'experiment-samples-nogit/large-csob'\n",
    "\n",
    "\n",
    "trainSampleGroupSize = 1\n",
    "testSampleGroupSize = 100\n",
    "\n",
    "IMAGE_WIDTH = 40\n",
    "IMAGE_HEIGHT = 60\n",
    "\n",
    "LR = 0.0001\n",
    "\n",
    "MODEL_NAME = 'prvy pokus'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOAD LIST OF AVAILABLE FILES\n",
    "recordings_path = sample_path + '/recordings'\n",
    "recordings = [d for d in listdir(recordings_path) if isdir(join(recordings_path, d))]\n",
    "paths = []\n",
    "for recording in recordings:\n",
    "    recording_path = recordings_path + '/' + recording\n",
    "    paths = paths + [(recording_path+'/'+f) for f in listdir(recording_path) if isfile(join(recording_path, f))]\n",
    "    \n",
    "# LOAD CORRESPONDING LABELS\n",
    "labels = pd.read_excel(sample_path+'/labels.xlsx', sheetname='labels')\n",
    "labels.scene = pd.to_numeric(labels.scene.replace('none','0'))\n",
    "labels = labels[labels.frame.isin([ntpath.basename(path) for path in paths])]\n",
    "\n",
    "# SAMPLE FRAMES (TODO poriadne)\n",
    "train_table = labels.groupby('scene', group_keys=False).apply(lambda x: x.sample(min(len(x), trainSampleGroupSize)))\n",
    "test_table = labels.groupby('scene', group_keys=False).apply(lambda x: x.sample(min(len(x), testSampleGroupSize)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_labels = labels.scene.unique()\n",
    "\n",
    "def create_label(scene):\n",
    "    res = []\n",
    "    for label in unique_labels:\n",
    "        if (label == scene):\n",
    "            res.append(1)\n",
    "        else:\n",
    "            res.append(0)\n",
    "    return np.array(res)\n",
    "\n",
    "def create_data(df):\n",
    "    data = []\n",
    "    for i, row in df.iterrows():\n",
    "        path = recordings_path+'/'+row.recording+'/'+row.frame\n",
    "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img_data = cv2.resize(img_data, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "        data.append([np.array(img_data), create_label(row.scene)])\n",
    "    shuffle(data)\n",
    "    return data\n",
    "\n",
    "train = create_data(train_table)\n",
    "test = create_data(test_table)\n",
    "\n",
    "# pootacat polia\n",
    "X_train = np.array([i[0] for i in train]).reshape(-1, IMAGE_WIDTH, IMAGE_HEIGHT, 1)\n",
    "y_train = [i[1] for i in train]\n",
    "X_test = np.array([i[0] for i in test]).reshape(-1, IMAGE_WIDTH, IMAGE_HEIGHT, 1)\n",
    "y_test = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "convnet = input_data(shape=[None, IMAGE_WIDTH, IMAGE_HEIGHT, 1], name='input')\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = fully_connected(convnet, 512, activation ='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "convnet = fully_connected(convnet, 6, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = tflearn.DNN(convnet, tensorboard_dir='log-final/csob-train1-2nd', tensorboard_verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: prvy pokus\n",
      "Log directory: log-final/csob-train1-2nd/\n",
      "---------------------------------\n",
      "Training samples: 6\n",
      "Validation samples: 600\n",
      "--\n",
      "Training Step: 1001  | total loss: \u001b[1m\u001b[32m0.18880\u001b[0m\u001b[0m | time: 1.893s\n",
      "| Adam | epoch: 1001 | loss: 0.18880 - acc: 0.9724 | val_loss: 3.50182 - val_acc: 0.2683 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1002  | total loss: \u001b[1m\u001b[32m0.18282\u001b[0m\u001b[0m | time: 1.222s\n",
      "| Adam | epoch: 1002 | loss: 0.18282 - acc: 0.9751 | val_loss: 3.57630 - val_acc: 0.2650 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1003  | total loss: \u001b[1m\u001b[32m0.17461\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1003 | loss: 0.17461 - acc: 0.9776 | val_loss: 3.57584 - val_acc: 0.2683 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1004  | total loss: \u001b[1m\u001b[32m0.16830\u001b[0m\u001b[0m | time: 1.042s\n",
      "| Adam | epoch: 1004 | loss: 0.16830 - acc: 0.9799 | val_loss: 3.58894 - val_acc: 0.2683 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1005  | total loss: \u001b[1m\u001b[32m0.16297\u001b[0m\u001b[0m | time: 1.633s\n",
      "| Adam | epoch: 1005 | loss: 0.16297 - acc: 0.9819 | val_loss: 3.69524 - val_acc: 0.2633 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1006  | total loss: \u001b[1m\u001b[32m0.15492\u001b[0m\u001b[0m | time: 1.272s\n",
      "| Adam | epoch: 1006 | loss: 0.15492 - acc: 0.9837 | val_loss: 3.74162 - val_acc: 0.2450 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1007  | total loss: \u001b[1m\u001b[32m0.14886\u001b[0m\u001b[0m | time: 1.175s\n",
      "| Adam | epoch: 1007 | loss: 0.14886 - acc: 0.9853 | val_loss: 3.68476 - val_acc: 0.2683 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1008  | total loss: \u001b[1m\u001b[32m0.14446\u001b[0m\u001b[0m | time: 1.041s\n",
      "| Adam | epoch: 1008 | loss: 0.14446 - acc: 0.9868 | val_loss: 3.73346 - val_acc: 0.2683 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1009  | total loss: \u001b[1m\u001b[32m0.13885\u001b[0m\u001b[0m | time: 1.034s\n",
      "| Adam | epoch: 1009 | loss: 0.13885 - acc: 0.9881 | val_loss: 3.79475 - val_acc: 0.2667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1010  | total loss: \u001b[1m\u001b[32m0.13494\u001b[0m\u001b[0m | time: 1.752s\n",
      "| Adam | epoch: 1010 | loss: 0.13494 - acc: 0.9893 | val_loss: 3.75754 - val_acc: 0.2700 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1011  | total loss: \u001b[1m\u001b[32m0.13557\u001b[0m\u001b[0m | time: 1.261s\n",
      "| Adam | epoch: 1011 | loss: 0.13557 - acc: 0.9904 | val_loss: 3.82537 - val_acc: 0.2650 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1012  | total loss: \u001b[1m\u001b[32m0.13144\u001b[0m\u001b[0m | time: 1.071s\n",
      "| Adam | epoch: 1012 | loss: 0.13144 - acc: 0.9913 | val_loss: 3.87033 - val_acc: 0.2650 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1013  | total loss: \u001b[1m\u001b[32m0.13046\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1013 | loss: 0.13046 - acc: 0.9922 | val_loss: 3.81616 - val_acc: 0.2700 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1014  | total loss: \u001b[1m\u001b[32m0.12673\u001b[0m\u001b[0m | time: 1.043s\n",
      "| Adam | epoch: 1014 | loss: 0.12673 - acc: 0.9930 | val_loss: 3.86594 - val_acc: 0.2683 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1015  | total loss: \u001b[1m\u001b[32m0.12447\u001b[0m\u001b[0m | time: 1.030s\n",
      "| Adam | epoch: 1015 | loss: 0.12447 - acc: 0.9937 | val_loss: 4.02213 - val_acc: 0.2150 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1016  | total loss: \u001b[1m\u001b[32m0.11856\u001b[0m\u001b[0m | time: 1.565s\n",
      "| Adam | epoch: 1016 | loss: 0.11856 - acc: 0.9943 | val_loss: 4.05643 - val_acc: 0.2150 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1017  | total loss: \u001b[1m\u001b[32m0.12114\u001b[0m\u001b[0m | time: 1.292s\n",
      "| Adam | epoch: 1017 | loss: 0.12114 - acc: 0.9782 | val_loss: 3.97808 - val_acc: 0.2650 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1018  | total loss: \u001b[1m\u001b[32m0.11737\u001b[0m\u001b[0m | time: 1.058s\n",
      "| Adam | epoch: 1018 | loss: 0.11737 - acc: 0.9804 | val_loss: 3.90468 - val_acc: 0.2583 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1019  | total loss: \u001b[1m\u001b[32m0.11197\u001b[0m\u001b[0m | time: 1.037s\n",
      "| Adam | epoch: 1019 | loss: 0.11197 - acc: 0.9824 | val_loss: 3.93569 - val_acc: 0.2667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1020  | total loss: \u001b[1m\u001b[32m0.11122\u001b[0m\u001b[0m | time: 1.573s\n",
      "| Adam | epoch: 1020 | loss: 0.11122 - acc: 0.9841 | val_loss: 4.06030 - val_acc: 0.2650 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1021  | total loss: \u001b[1m\u001b[32m0.10968\u001b[0m\u001b[0m | time: 1.157s\n",
      "| Adam | epoch: 1021 | loss: 0.10968 - acc: 0.9857 | val_loss: 4.06797 - val_acc: 0.2650 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1022  | total loss: \u001b[1m\u001b[32m0.11325\u001b[0m\u001b[0m | time: 1.042s\n",
      "| Adam | epoch: 1022 | loss: 0.11325 - acc: 0.9871 | val_loss: 3.96770 - val_acc: 0.2533 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1023  | total loss: \u001b[1m\u001b[32m0.11404\u001b[0m\u001b[0m | time: 1.477s\n",
      "| Adam | epoch: 1023 | loss: 0.11404 - acc: 0.9884 | val_loss: 3.98348 - val_acc: 0.2600 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1024  | total loss: \u001b[1m\u001b[32m0.11287\u001b[0m\u001b[0m | time: 1.365s\n",
      "| Adam | epoch: 1024 | loss: 0.11287 - acc: 0.9896 | val_loss: 4.11131 - val_acc: 0.2667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1025  | total loss: \u001b[1m\u001b[32m0.11191\u001b[0m\u001b[0m | time: 1.049s\n",
      "| Adam | epoch: 1025 | loss: 0.11191 - acc: 0.9906 | val_loss: 4.36095 - val_acc: 0.2233 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1026  | total loss: \u001b[1m\u001b[32m0.10899\u001b[0m\u001b[0m | time: 1.042s\n",
      "| Adam | epoch: 1026 | loss: 0.10899 - acc: 0.9916 | val_loss: 4.45049 - val_acc: 0.2283 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1027  | total loss: \u001b[1m\u001b[32m0.11922\u001b[0m\u001b[0m | time: 1.559s\n",
      "| Adam | epoch: 1027 | loss: 0.11922 - acc: 0.9757 | val_loss: 4.41130 - val_acc: 0.2283 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1028  | total loss: \u001b[1m\u001b[32m0.13467\u001b[0m\u001b[0m | time: 1.193s\n",
      "| Adam | epoch: 1028 | loss: 0.13467 - acc: 0.9615 | val_loss: 4.37771 - val_acc: 0.2283 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1029  | total loss: \u001b[1m\u001b[32m0.96883\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 1029 | loss: 0.96883 - acc: 0.8653 | val_loss: 4.20674 - val_acc: 0.2350 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1030  | total loss: \u001b[1m\u001b[32m0.89280\u001b[0m\u001b[0m | time: 1.042s\n",
      "| Adam | epoch: 1030 | loss: 0.89280 - acc: 0.8621 | val_loss: 3.92520 - val_acc: 0.2617 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1031  | total loss: \u001b[1m\u001b[32m0.81369\u001b[0m\u001b[0m | time: 1.528s\n",
      "| Adam | epoch: 1031 | loss: 0.81369 - acc: 0.8759 | val_loss: 3.81749 - val_acc: 0.2400 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1032  | total loss: \u001b[1m\u001b[32m0.74274\u001b[0m\u001b[0m | time: 1.131s\n",
      "| Adam | epoch: 1032 | loss: 0.74274 - acc: 0.8883 | val_loss: 3.82608 - val_acc: 0.2417 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1033  | total loss: \u001b[1m\u001b[32m0.68179\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1033 | loss: 0.68179 - acc: 0.8828 | val_loss: 3.96119 - val_acc: 0.2900 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1034  | total loss: \u001b[1m\u001b[32m0.62351\u001b[0m\u001b[0m | time: 1.531s\n",
      "| Adam | epoch: 1034 | loss: 0.62351 - acc: 0.8946 | val_loss: 4.13049 - val_acc: 0.2350 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1035  | total loss: \u001b[1m\u001b[32m0.57045\u001b[0m\u001b[0m | time: 1.311s\n",
      "| Adam | epoch: 1035 | loss: 0.57045 - acc: 0.9051 | val_loss: 4.13865 - val_acc: 0.2317 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1036  | total loss: \u001b[1m\u001b[32m0.52416\u001b[0m\u001b[0m | time: 1.225s\n",
      "| Adam | epoch: 1036 | loss: 0.52416 - acc: 0.9146 | val_loss: 3.99732 - val_acc: 0.2750 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1037  | total loss: \u001b[1m\u001b[32m0.48601\u001b[0m\u001b[0m | time: 1.042s\n",
      "| Adam | epoch: 1037 | loss: 0.48601 - acc: 0.9065 | val_loss: 3.83311 - val_acc: 0.2883 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1038  | total loss: \u001b[1m\u001b[32m0.96433\u001b[0m\u001b[0m | time: 1.741s\n",
      "| Adam | epoch: 1038 | loss: 0.96433 - acc: 0.8491 | val_loss: 3.81879 - val_acc: 0.2867 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1039  | total loss: \u001b[1m\u001b[32m0.87592\u001b[0m\u001b[0m | time: 1.390s\n",
      "| Adam | epoch: 1039 | loss: 0.87592 - acc: 0.8642 | val_loss: 3.69141 - val_acc: 0.2900 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1040  | total loss: \u001b[1m\u001b[32m0.79453\u001b[0m\u001b[0m | time: 1.070s\n",
      "| Adam | epoch: 1040 | loss: 0.79453 - acc: 0.8778 | val_loss: 3.70260 - val_acc: 0.2867 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1041  | total loss: \u001b[1m\u001b[32m0.72237\u001b[0m\u001b[0m | time: 1.038s\n",
      "| Adam | epoch: 1041 | loss: 0.72237 - acc: 0.8900 | val_loss: 3.84208 - val_acc: 0.2400 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1042  | total loss: \u001b[1m\u001b[32m0.65967\u001b[0m\u001b[0m | time: 1.501s\n",
      "| Adam | epoch: 1042 | loss: 0.65967 - acc: 0.9010 | val_loss: 3.83755 - val_acc: 0.2383 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1043  | total loss: \u001b[1m\u001b[32m0.60409\u001b[0m\u001b[0m | time: 1.188s\n",
      "| Adam | epoch: 1043 | loss: 0.60409 - acc: 0.9109 | val_loss: 3.70452 - val_acc: 0.2833 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1044  | total loss: \u001b[1m\u001b[32m0.55838\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 1044 | loss: 0.55838 - acc: 0.9032 | val_loss: 3.71183 - val_acc: 0.2833 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1045  | total loss: \u001b[1m\u001b[32m0.51187\u001b[0m\u001b[0m | time: 1.484s\n",
      "| Adam | epoch: 1045 | loss: 0.51187 - acc: 0.9128 | val_loss: 3.68680 - val_acc: 0.2683 -- iter: 6/6\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1046  | total loss: \u001b[1m\u001b[32m0.47002\u001b[0m\u001b[0m | time: 1.336s\n",
      "| Adam | epoch: 1046 | loss: 0.47002 - acc: 0.9216 | val_loss: 3.60617 - val_acc: 0.2683 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1047  | total loss: \u001b[1m\u001b[32m0.43215\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 1047 | loss: 0.43215 - acc: 0.9294 | val_loss: 3.63952 - val_acc: 0.2667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1048  | total loss: \u001b[1m\u001b[32m0.39768\u001b[0m\u001b[0m | time: 1.038s\n",
      "| Adam | epoch: 1048 | loss: 0.39768 - acc: 0.9365 | val_loss: 3.76255 - val_acc: 0.2217 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1049  | total loss: \u001b[1m\u001b[32m0.36343\u001b[0m\u001b[0m | time: 1.643s\n",
      "| Adam | epoch: 1049 | loss: 0.36343 - acc: 0.9428 | val_loss: 3.76589 - val_acc: 0.2217 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1050  | total loss: \u001b[1m\u001b[32m0.33789\u001b[0m\u001b[0m | time: 1.262s\n",
      "| Adam | epoch: 1050 | loss: 0.33789 - acc: 0.9485 | val_loss: 3.65973 - val_acc: 0.2650 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1051  | total loss: \u001b[1m\u001b[32m0.31256\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1051 | loss: 0.31256 - acc: 0.9537 | val_loss: 3.58624 - val_acc: 0.2417 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1052  | total loss: \u001b[1m\u001b[32m0.28542\u001b[0m\u001b[0m | time: 1.041s\n",
      "| Adam | epoch: 1052 | loss: 0.28542 - acc: 0.9583 | val_loss: 3.61287 - val_acc: 0.2667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1053  | total loss: \u001b[1m\u001b[32m0.26887\u001b[0m\u001b[0m | time: 1.563s\n",
      "| Adam | epoch: 1053 | loss: 0.26887 - acc: 0.9625 | val_loss: 3.74190 - val_acc: 0.2583 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1054  | total loss: \u001b[1m\u001b[32m0.25026\u001b[0m\u001b[0m | time: 1.152s\n",
      "| Adam | epoch: 1054 | loss: 0.25026 - acc: 0.9662 | val_loss: 3.75932 - val_acc: 0.2517 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1055  | total loss: \u001b[1m\u001b[32m0.23195\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 1055 | loss: 0.23195 - acc: 0.9696 | val_loss: 3.66796 - val_acc: 0.2667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1056  | total loss: \u001b[1m\u001b[32m0.21640\u001b[0m\u001b[0m | time: 1.678s\n",
      "| Adam | epoch: 1056 | loss: 0.21640 - acc: 0.9727 | val_loss: 3.59058 - val_acc: 0.2350 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1057  | total loss: \u001b[1m\u001b[32m0.20049\u001b[0m\u001b[0m | time: 1.208s\n",
      "| Adam | epoch: 1057 | loss: 0.20049 - acc: 0.9754 | val_loss: 3.60891 - val_acc: 0.2383 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1058  | total loss: \u001b[1m\u001b[32m0.19015\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1058 | loss: 0.19015 - acc: 0.9778 | val_loss: 3.72766 - val_acc: 0.2650 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1059  | total loss: \u001b[1m\u001b[32m0.17982\u001b[0m\u001b[0m | time: 1.038s\n",
      "| Adam | epoch: 1059 | loss: 0.17982 - acc: 0.9801 | val_loss: 3.86735 - val_acc: 0.2150 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1060  | total loss: \u001b[1m\u001b[32m0.67391\u001b[0m\u001b[0m | time: 1.868s\n",
      "| Adam | epoch: 1060 | loss: 0.67391 - acc: 0.9154 | val_loss: 3.87721 - val_acc: 0.2283 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1061  | total loss: \u001b[1m\u001b[32m0.61745\u001b[0m\u001b[0m | time: 1.132s\n",
      "| Adam | epoch: 1061 | loss: 0.61745 - acc: 0.9239 | val_loss: 3.76169 - val_acc: 0.2250 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1062  | total loss: \u001b[1m\u001b[32m0.56834\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 1062 | loss: 0.56834 - acc: 0.9315 | val_loss: 3.54148 - val_acc: 0.2667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1063  | total loss: \u001b[1m\u001b[32m0.52135\u001b[0m\u001b[0m | time: 1.547s\n",
      "| Adam | epoch: 1063 | loss: 0.52135 - acc: 0.9383 | val_loss: 3.47178 - val_acc: 0.2400 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1064  | total loss: \u001b[1m\u001b[32m0.47576\u001b[0m\u001b[0m | time: 1.143s\n",
      "| Adam | epoch: 1064 | loss: 0.47576 - acc: 0.9445 | val_loss: 3.51028 - val_acc: 0.2650 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1065  | total loss: \u001b[1m\u001b[32m0.43910\u001b[0m\u001b[0m | time: 1.045s\n",
      "| Adam | epoch: 1065 | loss: 0.43910 - acc: 0.9500 | val_loss: 3.68219 - val_acc: 0.2367 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1066  | total loss: \u001b[1m\u001b[32m0.40187\u001b[0m\u001b[0m | time: 1.556s\n",
      "| Adam | epoch: 1066 | loss: 0.40187 - acc: 0.9550 | val_loss: 3.71909 - val_acc: 0.2317 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1067  | total loss: \u001b[1m\u001b[32m0.36989\u001b[0m\u001b[0m | time: 1.152s\n",
      "| Adam | epoch: 1067 | loss: 0.36989 - acc: 0.9595 | val_loss: 3.61941 - val_acc: 0.2750 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1068  | total loss: \u001b[1m\u001b[32m0.34662\u001b[0m\u001b[0m | time: 1.045s\n",
      "| Adam | epoch: 1068 | loss: 0.34662 - acc: 0.9636 | val_loss: 3.42386 - val_acc: 0.2400 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1069  | total loss: \u001b[1m\u001b[32m0.31678\u001b[0m\u001b[0m | time: 1.037s\n",
      "| Adam | epoch: 1069 | loss: 0.31678 - acc: 0.9672 | val_loss: 3.37659 - val_acc: 0.2400 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1070  | total loss: \u001b[1m\u001b[32m0.29579\u001b[0m\u001b[0m | time: 1.538s\n",
      "| Adam | epoch: 1070 | loss: 0.29579 - acc: 0.9705 | val_loss: 3.42916 - val_acc: 0.2567 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1071  | total loss: \u001b[1m\u001b[32m0.28152\u001b[0m\u001b[0m | time: 1.191s\n",
      "| Adam | epoch: 1071 | loss: 0.28152 - acc: 0.9568 | val_loss: 3.61145 - val_acc: 0.2717 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1072  | total loss: \u001b[1m\u001b[32m0.26137\u001b[0m\u001b[0m | time: 1.045s\n",
      "| Adam | epoch: 1072 | loss: 0.26137 - acc: 0.9611 | val_loss: 3.66196 - val_acc: 0.2367 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1073  | total loss: \u001b[1m\u001b[32m0.24168\u001b[0m\u001b[0m | time: 1.040s\n",
      "| Adam | epoch: 1073 | loss: 0.24168 - acc: 0.9650 | val_loss: 3.57174 - val_acc: 0.2800 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1074  | total loss: \u001b[1m\u001b[32m0.22743\u001b[0m\u001b[0m | time: 1.037s\n",
      "| Adam | epoch: 1074 | loss: 0.22743 - acc: 0.9685 | val_loss: 3.38976 - val_acc: 0.2433 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1075  | total loss: \u001b[1m\u001b[32m0.21230\u001b[0m\u001b[0m | time: 1.523s\n",
      "| Adam | epoch: 1075 | loss: 0.21230 - acc: 0.9716 | val_loss: 3.35193 - val_acc: 0.2383 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1076  | total loss: \u001b[1m\u001b[32m0.20191\u001b[0m\u001b[0m | time: 1.126s\n",
      "| Adam | epoch: 1076 | loss: 0.20191 - acc: 0.9745 | val_loss: 3.41078 - val_acc: 0.2450 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1077  | total loss: \u001b[1m\u001b[32m0.19248\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 1077 | loss: 0.19248 - acc: 0.9770 | val_loss: 3.59744 - val_acc: 0.2800 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1078  | total loss: \u001b[1m\u001b[32m0.18022\u001b[0m\u001b[0m | time: 1.043s\n",
      "| Adam | epoch: 1078 | loss: 0.18022 - acc: 0.9793 | val_loss: 3.65730 - val_acc: 0.2383 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1079  | total loss: \u001b[1m\u001b[32m0.16786\u001b[0m\u001b[0m | time: 1.100s\n",
      "| Adam | epoch: 1079 | loss: 0.16786 - acc: 0.9814 | val_loss: 3.57837 - val_acc: 0.2750 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1080  | total loss: \u001b[1m\u001b[32m0.15713\u001b[0m\u001b[0m | time: 1.053s\n",
      "| Adam | epoch: 1080 | loss: 0.15713 - acc: 0.9833 | val_loss: 3.51383 - val_acc: 0.2667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1081  | total loss: \u001b[1m\u001b[32m0.14844\u001b[0m\u001b[0m | time: 1.036s\n",
      "| Adam | epoch: 1081 | loss: 0.14844 - acc: 0.9849 | val_loss: 3.57939 - val_acc: 0.2667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1082  | total loss: \u001b[1m\u001b[32m0.13832\u001b[0m\u001b[0m | time: 1.823s\n",
      "| Adam | epoch: 1082 | loss: 0.13832 - acc: 0.9864 | val_loss: 3.72286 - val_acc: 0.2350 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1083  | total loss: \u001b[1m\u001b[32m0.12969\u001b[0m\u001b[0m | time: 1.362s\n",
      "| Adam | epoch: 1083 | loss: 0.12969 - acc: 0.9878 | val_loss: 3.72025 - val_acc: 0.2217 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1084  | total loss: \u001b[1m\u001b[32m0.12498\u001b[0m\u001b[0m | time: 1.060s\n",
      "| Adam | epoch: 1084 | loss: 0.12498 - acc: 0.9890 | val_loss: 3.59372 - val_acc: 0.2650 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1085  | total loss: \u001b[1m\u001b[32m0.11981\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 1085 | loss: 0.11981 - acc: 0.9901 | val_loss: 3.58704 - val_acc: 0.2667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1086  | total loss: \u001b[1m\u001b[32m0.11198\u001b[0m\u001b[0m | time: 1.732s\n",
      "| Adam | epoch: 1086 | loss: 0.11198 - acc: 0.9911 | val_loss: 3.63212 - val_acc: 0.2667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1087  | total loss: \u001b[1m\u001b[32m0.10523\u001b[0m\u001b[0m | time: 1.215s\n",
      "| Adam | epoch: 1087 | loss: 0.10523 - acc: 0.9920 | val_loss: 3.73166 - val_acc: 0.2650 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1088  | total loss: \u001b[1m\u001b[32m0.09888\u001b[0m\u001b[0m | time: 1.054s\n",
      "| Adam | epoch: 1088 | loss: 0.09888 - acc: 0.9928 | val_loss: 3.70041 - val_acc: 0.2650 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1089  | total loss: \u001b[1m\u001b[32m0.09377\u001b[0m\u001b[0m | time: 1.038s\n",
      "| Adam | epoch: 1089 | loss: 0.09377 - acc: 0.9935 | val_loss: 3.66760 - val_acc: 0.2667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1090  | total loss: \u001b[1m\u001b[32m0.08927\u001b[0m\u001b[0m | time: 1.644s\n",
      "| Adam | epoch: 1090 | loss: 0.08927 - acc: 0.9942 | val_loss: 3.75051 - val_acc: 0.2650 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1091  | total loss: \u001b[1m\u001b[32m0.08540\u001b[0m\u001b[0m | time: 1.152s\n",
      "| Adam | epoch: 1091 | loss: 0.08540 - acc: 0.9947 | val_loss: 3.89393 - val_acc: 0.2183 -- iter: 6/6\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1092  | total loss: \u001b[1m\u001b[32m0.08258\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 1092 | loss: 0.08258 - acc: 0.9953 | val_loss: 3.89673 - val_acc: 0.2200 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1093  | total loss: \u001b[1m\u001b[32m0.08132\u001b[0m\u001b[0m | time: 1.526s\n",
      "| Adam | epoch: 1093 | loss: 0.08132 - acc: 0.9957 | val_loss: 3.77370 - val_acc: 0.2667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1094  | total loss: \u001b[1m\u001b[32m0.07785\u001b[0m\u001b[0m | time: 1.198s\n",
      "| Adam | epoch: 1094 | loss: 0.07785 - acc: 0.9962 | val_loss: 3.71729 - val_acc: 0.2683 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1095  | total loss: \u001b[1m\u001b[32m0.07424\u001b[0m\u001b[0m | time: 1.045s\n",
      "| Adam | epoch: 1095 | loss: 0.07424 - acc: 0.9966 | val_loss: 3.77741 - val_acc: 0.2667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1096  | total loss: \u001b[1m\u001b[32m0.07429\u001b[0m\u001b[0m | time: 1.037s\n",
      "| Adam | epoch: 1096 | loss: 0.07429 - acc: 0.9969 | val_loss: 3.97007 - val_acc: 0.2200 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1097  | total loss: \u001b[1m\u001b[32m0.07066\u001b[0m\u001b[0m | time: 1.534s\n",
      "| Adam | epoch: 1097 | loss: 0.07066 - acc: 0.9972 | val_loss: 4.01811 - val_acc: 0.2183 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1098  | total loss: \u001b[1m\u001b[32m0.06953\u001b[0m\u001b[0m | time: 1.321s\n",
      "| Adam | epoch: 1098 | loss: 0.06953 - acc: 0.9975 | val_loss: 3.92314 - val_acc: 0.2650 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1099  | total loss: \u001b[1m\u001b[32m0.06739\u001b[0m\u001b[0m | time: 1.201s\n",
      "| Adam | epoch: 1099 | loss: 0.06739 - acc: 0.9977 | val_loss: 3.73630 - val_acc: 0.2350 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1100  | total loss: \u001b[1m\u001b[32m0.06493\u001b[0m\u001b[0m | time: 1.052s\n",
      "| Adam | epoch: 1100 | loss: 0.06493 - acc: 0.9980 | val_loss: 3.70448 - val_acc: 0.2333 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1101  | total loss: \u001b[1m\u001b[32m0.06709\u001b[0m\u001b[0m | time: 1.845s\n",
      "| Adam | epoch: 1101 | loss: 0.06709 - acc: 0.9982 | val_loss: 3.72047 - val_acc: 0.2367 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1102  | total loss: \u001b[1m\u001b[32m0.47169\u001b[0m\u001b[0m | time: 1.330s\n",
      "| Adam | epoch: 1102 | loss: 0.47169 - acc: 0.9317 | val_loss: 3.85768 - val_acc: 0.2683 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1103  | total loss: \u001b[1m\u001b[32m0.43796\u001b[0m\u001b[0m | time: 1.062s\n",
      "| Adam | epoch: 1103 | loss: 0.43796 - acc: 0.9218 | val_loss: 4.15610 - val_acc: 0.2283 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1104  | total loss: \u001b[1m\u001b[32m0.39933\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 1104 | loss: 0.39933 - acc: 0.9297 | val_loss: 4.28864 - val_acc: 0.2283 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1105  | total loss: \u001b[1m\u001b[32m0.37195\u001b[0m\u001b[0m | time: 1.038s\n",
      "| Adam | epoch: 1105 | loss: 0.37195 - acc: 0.9200 | val_loss: 4.25545 - val_acc: 0.2283 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1106  | total loss: \u001b[1m\u001b[32m0.36661\u001b[0m\u001b[0m | time: 1.643s\n",
      "| Adam | epoch: 1106 | loss: 0.36661 - acc: 0.9114 | val_loss: 4.06683 - val_acc: 0.2317 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1107  | total loss: \u001b[1m\u001b[32m0.35833\u001b[0m\u001b[0m | time: 1.169s\n",
      "| Adam | epoch: 1107 | loss: 0.35833 - acc: 0.9036 | val_loss: 3.79808 - val_acc: 0.2700 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1108  | total loss: \u001b[1m\u001b[32m1.08016\u001b[0m\u001b[0m | time: 1.220s\n",
      "| Adam | epoch: 1108 | loss: 1.08016 - acc: 0.8299 | val_loss: 3.66860 - val_acc: 0.2667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1109  | total loss: \u001b[1m\u001b[32m0.97543\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 1109 | loss: 0.97543 - acc: 0.8469 | val_loss: 3.67992 - val_acc: 0.2700 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1110  | total loss: \u001b[1m\u001b[32m0.88434\u001b[0m\u001b[0m | time: 1.549s\n",
      "| Adam | epoch: 1110 | loss: 0.88434 - acc: 0.8622 | val_loss: 3.83670 - val_acc: 0.2650 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1111  | total loss: \u001b[1m\u001b[32m0.80019\u001b[0m\u001b[0m | time: 1.316s\n",
      "| Adam | epoch: 1111 | loss: 0.80019 - acc: 0.8760 | val_loss: 3.84011 - val_acc: 0.2383 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1112  | total loss: \u001b[1m\u001b[32m0.72562\u001b[0m\u001b[0m | time: 1.043s\n",
      "| Adam | epoch: 1112 | loss: 0.72562 - acc: 0.8884 | val_loss: 3.70250 - val_acc: 0.2833 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1113  | total loss: \u001b[1m\u001b[32m0.65767\u001b[0m\u001b[0m | time: 1.038s\n",
      "| Adam | epoch: 1113 | loss: 0.65767 - acc: 0.8995 | val_loss: 3.58021 - val_acc: 0.2833 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1114  | total loss: \u001b[1m\u001b[32m1.26597\u001b[0m\u001b[0m | time: 1.634s\n",
      "| Adam | epoch: 1114 | loss: 1.26597 - acc: 0.8096 | val_loss: 3.61603 - val_acc: 0.2833 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1115  | total loss: \u001b[1m\u001b[32m1.14418\u001b[0m\u001b[0m | time: 1.222s\n",
      "| Adam | epoch: 1115 | loss: 1.14418 - acc: 0.8286 | val_loss: 3.51463 - val_acc: 0.2833 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1116  | total loss: \u001b[1m\u001b[32m1.03481\u001b[0m\u001b[0m | time: 1.045s\n",
      "| Adam | epoch: 1116 | loss: 1.03481 - acc: 0.8458 | val_loss: 3.46743 - val_acc: 0.2850 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1117  | total loss: \u001b[1m\u001b[32m0.93526\u001b[0m\u001b[0m | time: 1.667s\n",
      "| Adam | epoch: 1117 | loss: 0.93526 - acc: 0.8612 | val_loss: 3.42264 - val_acc: 0.2850 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1118  | total loss: \u001b[1m\u001b[32m0.84520\u001b[0m\u001b[0m | time: 1.196s\n",
      "| Adam | epoch: 1118 | loss: 0.84520 - acc: 0.8751 | val_loss: 3.43597 - val_acc: 0.2833 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1119  | total loss: \u001b[1m\u001b[32m0.76572\u001b[0m\u001b[0m | time: 1.081s\n",
      "| Adam | epoch: 1119 | loss: 0.76572 - acc: 0.8876 | val_loss: 3.44612 - val_acc: 0.2833 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1120  | total loss: \u001b[1m\u001b[32m0.69333\u001b[0m\u001b[0m | time: 1.039s\n",
      "| Adam | epoch: 1120 | loss: 0.69333 - acc: 0.8988 | val_loss: 3.49218 - val_acc: 0.2833 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1121  | total loss: \u001b[1m\u001b[32m0.62684\u001b[0m\u001b[0m | time: 1.577s\n",
      "| Adam | epoch: 1121 | loss: 0.62684 - acc: 0.9089 | val_loss: 3.51923 - val_acc: 0.2783 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1122  | total loss: \u001b[1m\u001b[32m1.30525\u001b[0m\u001b[0m | time: 1.203s\n",
      "| Adam | epoch: 1122 | loss: 1.30525 - acc: 0.8180 | val_loss: 3.41690 - val_acc: 0.2833 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1123  | total loss: \u001b[1m\u001b[32m1.18040\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 1123 | loss: 1.18040 - acc: 0.8362 | val_loss: 3.24801 - val_acc: 0.2400 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1124  | total loss: \u001b[1m\u001b[32m1.06665\u001b[0m\u001b[0m | time: 1.664s\n",
      "| Adam | epoch: 1124 | loss: 1.06665 - acc: 0.8526 | val_loss: 3.21812 - val_acc: 0.2367 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1125  | total loss: \u001b[1m\u001b[32m0.96830\u001b[0m\u001b[0m | time: 1.145s\n",
      "| Adam | epoch: 1125 | loss: 0.96830 - acc: 0.8673 | val_loss: 3.29125 - val_acc: 0.2683 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1126  | total loss: \u001b[1m\u001b[32m0.87705\u001b[0m\u001b[0m | time: 1.045s\n",
      "| Adam | epoch: 1126 | loss: 0.87705 - acc: 0.8806 | val_loss: 3.48572 - val_acc: 0.2367 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1127  | total loss: \u001b[1m\u001b[32m0.79605\u001b[0m\u001b[0m | time: 1.035s\n",
      "| Adam | epoch: 1127 | loss: 0.79605 - acc: 0.8926 | val_loss: 3.55410 - val_acc: 0.2267 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1128  | total loss: \u001b[1m\u001b[32m0.72198\u001b[0m\u001b[0m | time: 1.036s\n",
      "| Adam | epoch: 1128 | loss: 0.72198 - acc: 0.9033 | val_loss: 3.48451 - val_acc: 0.2350 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1129  | total loss: \u001b[1m\u001b[32m0.65946\u001b[0m\u001b[0m | time: 1.567s\n",
      "| Adam | epoch: 1129 | loss: 0.65946 - acc: 0.9130 | val_loss: 3.31898 - val_acc: 0.2683 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1130  | total loss: \u001b[1m\u001b[32m0.59984\u001b[0m\u001b[0m | time: 1.262s\n",
      "| Adam | epoch: 1130 | loss: 0.59984 - acc: 0.9217 | val_loss: 3.29374 - val_acc: 0.2667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1131  | total loss: \u001b[1m\u001b[32m0.54504\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 1131 | loss: 0.54504 - acc: 0.9295 | val_loss: 3.37293 - val_acc: 0.2683 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1132  | total loss: \u001b[1m\u001b[32m0.49647\u001b[0m\u001b[0m | time: 1.871s\n",
      "| Adam | epoch: 1132 | loss: 0.49647 - acc: 0.9366 | val_loss: 3.50892 - val_acc: 0.2383 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1133  | total loss: \u001b[1m\u001b[32m0.45056\u001b[0m\u001b[0m | time: 1.369s\n",
      "| Adam | epoch: 1133 | loss: 0.45056 - acc: 0.9429 | val_loss: 3.51879 - val_acc: 0.2367 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1134  | total loss: \u001b[1m\u001b[32m0.41278\u001b[0m\u001b[0m | time: 1.040s\n",
      "| Adam | epoch: 1134 | loss: 0.41278 - acc: 0.9486 | val_loss: 3.41847 - val_acc: 0.2650 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1135  | total loss: \u001b[1m\u001b[32m0.37666\u001b[0m\u001b[0m | time: 1.583s\n",
      "| Adam | epoch: 1135 | loss: 0.37666 - acc: 0.9537 | val_loss: 3.32663 - val_acc: 0.2533 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1136  | total loss: \u001b[1m\u001b[32m0.34563\u001b[0m\u001b[0m | time: 1.132s\n",
      "| Adam | epoch: 1136 | loss: 0.34563 - acc: 0.9584 | val_loss: 3.34518 - val_acc: 0.2550 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1137  | total loss: \u001b[1m\u001b[32m0.31741\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 1137 | loss: 0.31741 - acc: 0.9625 | val_loss: 3.46727 - val_acc: 0.2650 -- iter: 6/6\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1138  | total loss: \u001b[1m\u001b[32m0.29386\u001b[0m\u001b[0m | time: 1.043s\n",
      "| Adam | epoch: 1138 | loss: 0.29386 - acc: 0.9663 | val_loss: 3.66667 - val_acc: 0.2317 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1139  | total loss: \u001b[1m\u001b[32m0.26799\u001b[0m\u001b[0m | time: 1.041s\n",
      "| Adam | epoch: 1139 | loss: 0.26799 - acc: 0.9697 | val_loss: 3.73069 - val_acc: 0.2283 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1140  | total loss: \u001b[1m\u001b[32m0.25257\u001b[0m\u001b[0m | time: 1.615s\n",
      "| Adam | epoch: 1140 | loss: 0.25257 - acc: 0.9727 | val_loss: 3.64946 - val_acc: 0.2383 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1141  | total loss: \u001b[1m\u001b[32m0.24065\u001b[0m\u001b[0m | time: 1.146s\n",
      "| Adam | epoch: 1141 | loss: 0.24065 - acc: 0.9754 | val_loss: 3.46414 - val_acc: 0.2700 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1142  | total loss: \u001b[1m\u001b[32m0.22235\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 1142 | loss: 0.22235 - acc: 0.9779 | val_loss: 3.42699 - val_acc: 0.2483 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1143  | total loss: \u001b[1m\u001b[32m0.20377\u001b[0m\u001b[0m | time: 1.040s\n",
      "| Adam | epoch: 1143 | loss: 0.20377 - acc: 0.9801 | val_loss: 3.50172 - val_acc: 0.2700 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1144  | total loss: \u001b[1m\u001b[32m0.18964\u001b[0m\u001b[0m | time: 1.552s\n",
      "| Adam | epoch: 1144 | loss: 0.18964 - acc: 0.9821 | val_loss: 3.70564 - val_acc: 0.2517 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1145  | total loss: \u001b[1m\u001b[32m0.17516\u001b[0m\u001b[0m | time: 1.186s\n",
      "| Adam | epoch: 1145 | loss: 0.17516 - acc: 0.9839 | val_loss: 3.77135 - val_acc: 0.2367 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1146  | total loss: \u001b[1m\u001b[32m0.16143\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 1146 | loss: 0.16143 - acc: 0.9855 | val_loss: 3.69150 - val_acc: 0.2800 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1147  | total loss: \u001b[1m\u001b[32m0.15205\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 1147 | loss: 0.15205 - acc: 0.9869 | val_loss: 3.50498 - val_acc: 0.2600 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1148  | total loss: \u001b[1m\u001b[32m0.14096\u001b[0m\u001b[0m | time: 1.645s\n",
      "| Adam | epoch: 1148 | loss: 0.14096 - acc: 0.9882 | val_loss: 3.47016 - val_acc: 0.2400 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1149  | total loss: \u001b[1m\u001b[32m0.13523\u001b[0m\u001b[0m | time: 1.162s\n",
      "| Adam | epoch: 1149 | loss: 0.13523 - acc: 0.9894 | val_loss: 3.54403 - val_acc: 0.2717 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1150  | total loss: \u001b[1m\u001b[32m0.13217\u001b[0m\u001b[0m | time: 1.045s\n",
      "| Adam | epoch: 1150 | loss: 0.13217 - acc: 0.9905 | val_loss: 3.74989 - val_acc: 0.2800 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1151  | total loss: \u001b[1m\u001b[32m0.12487\u001b[0m\u001b[0m | time: 1.039s\n",
      "| Adam | epoch: 1151 | loss: 0.12487 - acc: 0.9914 | val_loss: 3.81467 - val_acc: 0.2383 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1152  | total loss: \u001b[1m\u001b[32m0.11907\u001b[0m\u001b[0m | time: 1.039s\n",
      "| Adam | epoch: 1152 | loss: 0.11907 - acc: 0.9923 | val_loss: 3.73552 - val_acc: 0.2800 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1153  | total loss: \u001b[1m\u001b[32m0.11302\u001b[0m\u001b[0m | time: 1.542s\n",
      "| Adam | epoch: 1153 | loss: 0.11302 - acc: 0.9931 | val_loss: 3.55324 - val_acc: 0.2417 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1154  | total loss: \u001b[1m\u001b[32m0.10466\u001b[0m\u001b[0m | time: 1.196s\n",
      "| Adam | epoch: 1154 | loss: 0.10466 - acc: 0.9938 | val_loss: 3.52337 - val_acc: 0.2367 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1155  | total loss: \u001b[1m\u001b[32m0.10201\u001b[0m\u001b[0m | time: 1.059s\n",
      "| Adam | epoch: 1155 | loss: 0.10201 - acc: 0.9944 | val_loss: 3.59531 - val_acc: 0.2583 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1156  | total loss: \u001b[1m\u001b[32m0.09864\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 1156 | loss: 0.09864 - acc: 0.9949 | val_loss: 3.80089 - val_acc: 0.2800 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1157  | total loss: \u001b[1m\u001b[32m0.09351\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 1157 | loss: 0.09351 - acc: 0.9954 | val_loss: 3.86667 - val_acc: 0.2667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1158  | total loss: \u001b[1m\u001b[32m0.08777\u001b[0m\u001b[0m | time: 1.034s\n",
      "| Adam | epoch: 1158 | loss: 0.08777 - acc: 0.9959 | val_loss: 3.78847 - val_acc: 0.2750 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1159  | total loss: \u001b[1m\u001b[32m0.08387\u001b[0m\u001b[0m | time: 1.547s\n",
      "| Adam | epoch: 1159 | loss: 0.08387 - acc: 0.9963 | val_loss: 3.63259 - val_acc: 0.2717 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1160  | total loss: \u001b[1m\u001b[32m0.52170\u001b[0m\u001b[0m | time: 1.183s\n",
      "| Adam | epoch: 1160 | loss: 0.52170 - acc: 0.9300 | val_loss: 3.61839 - val_acc: 0.2717 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1161  | total loss: \u001b[1m\u001b[32m0.47347\u001b[0m\u001b[0m | time: 1.045s\n",
      "| Adam | epoch: 1161 | loss: 0.47347 - acc: 0.9370 | val_loss: 3.73738 - val_acc: 0.2817 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1162  | total loss: \u001b[1m\u001b[32m0.43138\u001b[0m\u001b[0m | time: 1.045s\n",
      "| Adam | epoch: 1162 | loss: 0.43138 - acc: 0.9433 | val_loss: 3.71844 - val_acc: 0.2833 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1163  | total loss: \u001b[1m\u001b[32m0.39195\u001b[0m\u001b[0m | time: 1.590s\n",
      "| Adam | epoch: 1163 | loss: 0.39195 - acc: 0.9490 | val_loss: 3.57353 - val_acc: 0.2850 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1164  | total loss: \u001b[1m\u001b[32m0.35513\u001b[0m\u001b[0m | time: 1.197s\n",
      "| Adam | epoch: 1164 | loss: 0.35513 - acc: 0.9541 | val_loss: 3.57559 - val_acc: 0.2850 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1165  | total loss: \u001b[1m\u001b[32m0.32268\u001b[0m\u001b[0m | time: 1.043s\n",
      "| Adam | epoch: 1165 | loss: 0.32268 - acc: 0.9587 | val_loss: 3.71180 - val_acc: 0.2833 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1166  | total loss: \u001b[1m\u001b[32m0.29511\u001b[0m\u001b[0m | time: 1.517s\n",
      "| Adam | epoch: 1166 | loss: 0.29511 - acc: 0.9628 | val_loss: 3.70588 - val_acc: 0.2833 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1167  | total loss: \u001b[1m\u001b[32m0.26962\u001b[0m\u001b[0m | time: 1.191s\n",
      "| Adam | epoch: 1167 | loss: 0.26962 - acc: 0.9665 | val_loss: 3.57252 - val_acc: 0.2833 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1168  | total loss: \u001b[1m\u001b[32m0.24618\u001b[0m\u001b[0m | time: 1.051s\n",
      "| Adam | epoch: 1168 | loss: 0.24618 - acc: 0.9699 | val_loss: 3.58443 - val_acc: 0.2800 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1169  | total loss: \u001b[1m\u001b[32m0.22471\u001b[0m\u001b[0m | time: 1.041s\n",
      "| Adam | epoch: 1169 | loss: 0.22471 - acc: 0.9729 | val_loss: 3.72580 - val_acc: 0.2800 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1170  | total loss: \u001b[1m\u001b[32m0.20691\u001b[0m\u001b[0m | time: 1.659s\n",
      "| Adam | epoch: 1170 | loss: 0.20691 - acc: 0.9756 | val_loss: 3.72520 - val_acc: 0.2800 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1171  | total loss: \u001b[1m\u001b[32m0.19018\u001b[0m\u001b[0m | time: 1.259s\n",
      "| Adam | epoch: 1171 | loss: 0.19018 - acc: 0.9780 | val_loss: 3.81782 - val_acc: 0.2367 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1172  | total loss: \u001b[1m\u001b[32m0.82245\u001b[0m\u001b[0m | time: 1.073s\n",
      "| Adam | epoch: 1172 | loss: 0.82245 - acc: 0.8802 | val_loss: 3.76147 - val_acc: 0.2700 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1173  | total loss: \u001b[1m\u001b[32m0.74534\u001b[0m\u001b[0m | time: 1.035s\n",
      "| Adam | epoch: 1173 | loss: 0.74534 - acc: 0.8922 | val_loss: 3.59056 - val_acc: 0.2683 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1174  | total loss: \u001b[1m\u001b[32m0.67376\u001b[0m\u001b[0m | time: 1.652s\n",
      "| Adam | epoch: 1174 | loss: 0.67376 - acc: 0.9030 | val_loss: 3.57063 - val_acc: 0.2683 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1175  | total loss: \u001b[1m\u001b[32m0.60851\u001b[0m\u001b[0m | time: 1.165s\n",
      "| Adam | epoch: 1175 | loss: 0.60851 - acc: 0.9127 | val_loss: 3.53819 - val_acc: 0.2650 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1176  | total loss: \u001b[1m\u001b[32m0.86380\u001b[0m\u001b[0m | time: 1.079s\n",
      "| Adam | epoch: 1176 | loss: 0.86380 - acc: 0.8714 | val_loss: 3.59066 - val_acc: 0.2700 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1177  | total loss: \u001b[1m\u001b[32m0.78029\u001b[0m\u001b[0m | time: 1.033s\n",
      "| Adam | epoch: 1177 | loss: 0.78029 - acc: 0.8843 | val_loss: 3.56190 - val_acc: 0.2650 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1178  | total loss: \u001b[1m\u001b[32m0.70503\u001b[0m\u001b[0m | time: 1.548s\n",
      "| Adam | epoch: 1178 | loss: 0.70503 - acc: 0.8959 | val_loss: 3.51584 - val_acc: 0.2650 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1179  | total loss: \u001b[1m\u001b[32m0.63657\u001b[0m\u001b[0m | time: 1.177s\n",
      "| Adam | epoch: 1179 | loss: 0.63657 - acc: 0.9063 | val_loss: 3.40599 - val_acc: 0.2667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1180  | total loss: \u001b[1m\u001b[32m1.00421\u001b[0m\u001b[0m | time: 1.044s\n",
      "| Adam | epoch: 1180 | loss: 1.00421 - acc: 0.8323 | val_loss: 3.40872 - val_acc: 0.2633 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1181  | total loss: \u001b[1m\u001b[32m0.90693\u001b[0m\u001b[0m | time: 1.826s\n",
      "| Adam | epoch: 1181 | loss: 0.90693 - acc: 0.8491 | val_loss: 3.51542 - val_acc: 0.2550 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1182  | total loss: \u001b[1m\u001b[32m0.82121\u001b[0m\u001b[0m | time: 1.511s\n",
      "| Adam | epoch: 1182 | loss: 0.82121 - acc: 0.8642 | val_loss: 3.50751 - val_acc: 0.2233 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1183  | total loss: \u001b[1m\u001b[32m0.74339\u001b[0m\u001b[0m | time: 1.042s\n",
      "| Adam | epoch: 1183 | loss: 0.74339 - acc: 0.8778 | val_loss: 3.40143 - val_acc: 0.2650 -- iter: 6/6\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1184  | total loss: \u001b[1m\u001b[32m0.67737\u001b[0m\u001b[0m | time: 1.572s\n",
      "| Adam | epoch: 1184 | loss: 0.67737 - acc: 0.8900 | val_loss: 3.23525 - val_acc: 0.2383 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1185  | total loss: \u001b[1m\u001b[32m0.61339\u001b[0m\u001b[0m | time: 1.156s\n",
      "| Adam | epoch: 1185 | loss: 0.61339 - acc: 0.9010 | val_loss: 3.18034 - val_acc: 0.2367 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1186  | total loss: \u001b[1m\u001b[32m0.55927\u001b[0m\u001b[0m | time: 1.043s\n",
      "| Adam | epoch: 1186 | loss: 0.55927 - acc: 0.9109 | val_loss: 3.20500 - val_acc: 0.2383 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1187  | total loss: \u001b[1m\u001b[32m0.51545\u001b[0m\u001b[0m | time: 1.473s\n",
      "| Adam | epoch: 1187 | loss: 0.51545 - acc: 0.9198 | val_loss: 3.32180 - val_acc: 0.2667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1188  | total loss: \u001b[1m\u001b[32m0.46934\u001b[0m\u001b[0m | time: 1.252s\n",
      "| Adam | epoch: 1188 | loss: 0.46934 - acc: 0.9278 | val_loss: 3.40888 - val_acc: 0.2383 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1189  | total loss: \u001b[1m\u001b[32m0.42632\u001b[0m\u001b[0m | time: 1.047s\n",
      "| Adam | epoch: 1189 | loss: 0.42632 - acc: 0.9350 | val_loss: 3.38953 - val_acc: 0.2550 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1190  | total loss: \u001b[1m\u001b[32m0.38922\u001b[0m\u001b[0m | time: 1.041s\n",
      "| Adam | epoch: 1190 | loss: 0.38922 - acc: 0.9415 | val_loss: 3.27801 - val_acc: 0.2683 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1191  | total loss: \u001b[1m\u001b[32m0.35434\u001b[0m\u001b[0m | time: 1.546s\n",
      "| Adam | epoch: 1191 | loss: 0.35434 - acc: 0.9474 | val_loss: 3.23583 - val_acc: 0.2700 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1192  | total loss: \u001b[1m\u001b[32m0.32484\u001b[0m\u001b[0m | time: 1.121s\n",
      "| Adam | epoch: 1192 | loss: 0.32484 - acc: 0.9526 | val_loss: 3.29382 - val_acc: 0.2717 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1193  | total loss: \u001b[1m\u001b[32m0.29650\u001b[0m\u001b[0m | time: 1.046s\n",
      "| Adam | epoch: 1193 | loss: 0.29650 - acc: 0.9574 | val_loss: 3.45839 - val_acc: 0.2383 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1194  | total loss: \u001b[1m\u001b[32m0.27041\u001b[0m\u001b[0m | time: 1.724s\n",
      "| Adam | epoch: 1194 | loss: 0.27041 - acc: 0.9616 | val_loss: 3.51051 - val_acc: 0.2350 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1195  | total loss: \u001b[1m\u001b[32m0.24820\u001b[0m\u001b[0m | time: 1.110s\n",
      "| Adam | epoch: 1195 | loss: 0.24820 - acc: 0.9655 | val_loss: 3.43699 - val_acc: 0.2817 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1196  | total loss: \u001b[1m\u001b[32m0.23071\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1196 | loss: 0.23071 - acc: 0.9689 | val_loss: 3.28305 - val_acc: 0.2717 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1197  | total loss: \u001b[1m\u001b[32m0.21095\u001b[0m\u001b[0m | time: 1.522s\n",
      "| Adam | epoch: 1197 | loss: 0.21095 - acc: 0.9720 | val_loss: 3.25736 - val_acc: 0.2383 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1198  | total loss: \u001b[1m\u001b[32m0.19338\u001b[0m\u001b[0m | time: 1.177s\n",
      "| Adam | epoch: 1198 | loss: 0.19338 - acc: 0.9748 | val_loss: 3.31952 - val_acc: 0.2717 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1199  | total loss: \u001b[1m\u001b[32m0.18175\u001b[0m\u001b[0m | time: 1.048s\n",
      "| Adam | epoch: 1199 | loss: 0.18175 - acc: 0.9773 | val_loss: 3.49320 - val_acc: 0.2817 -- iter: 6/6\n",
      "--\n",
      "Training Step: 1200  | total loss: \u001b[1m\u001b[32m0.16829\u001b[0m\u001b[0m | time: 1.043s\n",
      "| Adam | epoch: 1200 | loss: 0.16829 - acc: 0.9796 | val_loss: 3.55032 - val_acc: 0.2750 -- iter: 6/6\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit (X_train, \n",
    "           y_train, \n",
    "           n_epoch=200, \n",
    "           validation_set=(X_test, y_test),\n",
    "           snapshot_step = 500,\n",
    "           show_metric = True,\n",
    "           run_id = MODEL_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
